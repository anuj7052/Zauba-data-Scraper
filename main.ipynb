{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>098739 30018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'+91-11-26382324'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>'+91-9740000662'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Phone\n",
       "0                 NaN\n",
       "1        098739 30018\n",
       "2                 NaN\n",
       "3                 NaN\n",
       "4   '+91-11-26382324'\n",
       "..                ...\n",
       "95                NaN\n",
       "96                NaN\n",
       "97   '+91-9740000662'\n",
       "98                NaN\n",
       "99                NaN\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "phone_numbers=accounts_data_df.loc[:, ['Phone']]\n",
    "phone_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Phone Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Standardized Phone\n",
      "0                None\n",
      "1      +91 9873930018\n",
      "2                None\n",
      "3                None\n",
      "4        911126382324\n",
      "..                ...\n",
      "95               None\n",
      "96               None\n",
      "97       919740000662\n",
      "98               None\n",
      "99               None\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to clean phone numbers\n",
    "def standardize_phone_number(phone):\n",
    "    if pd.isna(phone):\n",
    "        return None\n",
    "    \n",
    "    # Remove all non-numeric characters\n",
    "    cleaned_phone = re.sub(r'\\D', '', phone)\n",
    "    \n",
    "    # Ensure the phone number is in the format you want\n",
    "    # For example, assuming you want international format: +<country_code> <phone_number>\n",
    "    if len(cleaned_phone) == 10:\n",
    "        return '+91 ' + cleaned_phone  # Assuming +91 is the country code\n",
    "    elif len(cleaned_phone) == 11 and cleaned_phone.startswith('0'):\n",
    "        return '+91 ' + cleaned_phone[1:]  # Removing leading zero for the country code\n",
    "    else:\n",
    "        return cleaned_phone\n",
    "\n",
    "# Apply the function to the 'Phone' column\n",
    "phone_numbers['Standardized Phone'] = phone_numbers['Phone'].apply(standardize_phone_number)\n",
    "\n",
    "# Remove the original column if no longer needed\n",
    "phone_numbers = phone_numbers.drop(columns=['Phone'])\n",
    "\n",
    "# Display the result\n",
    "print(phone_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Standardized Phone\n",
      "0                None\n",
      "1      +91 9873930018\n",
      "2                None\n",
      "3                None\n",
      "4       +911126382324\n",
      "..                ...\n",
      "95               None\n",
      "96               None\n",
      "97      +919740000662\n",
      "98               None\n",
      "99               None\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnujSingh\\AppData\\Local\\Temp\\ipykernel_13444\\4013032854.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phone_numbers['Standardized Phone'] = phone_numbers['Phone'].apply(standardize_phone_number)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the 'Phone' column\n",
    "phone_numbers = accounts_data_df[['Phone']]\n",
    "\n",
    "# Function to standardize phone numbers\n",
    "def standardize_phone_number(phone):\n",
    "    if pd.isna(phone):\n",
    "        return None\n",
    "    \n",
    "    # Remove all non-numeric characters\n",
    "    cleaned_phone = re.sub(r'\\D', '', phone)\n",
    "    \n",
    "    # Standardize to international format\n",
    "    if len(cleaned_phone) == 10:\n",
    "        return '+91 ' + cleaned_phone  # Assuming +91 is the country code\n",
    "    elif len(cleaned_phone) == 11 and cleaned_phone.startswith('0'):\n",
    "        return '+91 ' + cleaned_phone[1:]  # Removing leading zero for the country code\n",
    "    elif len(cleaned_phone) == 12 and cleaned_phone.startswith('91'):\n",
    "        return '+' + cleaned_phone  # Already in international format, just add '+'\n",
    "    else:\n",
    "        return cleaned_phone  # Return as is if not fitting expected formats\n",
    "\n",
    "# Apply the standardization function\n",
    "phone_numbers['Standardized Phone'] = phone_numbers['Phone'].apply(standardize_phone_number)\n",
    "\n",
    "# Optionally, drop the old 'Phone' column\n",
    "phone_numbers = phone_numbers.drop(columns=['Phone'])\n",
    "\n",
    "# Display the standardized phone numbers\n",
    "print(phone_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>560091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>400028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zipcode\n",
       "0    32819\n",
       "1   201301\n",
       "2   123501\n",
       "3   122002\n",
       "4   110020\n",
       "..     ...\n",
       "95     NaN\n",
       "96     NaN\n",
       "97  560091\n",
       "98     NaN\n",
       "99  400028\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "Zipcode=accounts_data_df.loc[:, ['Zipcode']]\n",
    "\n",
    "\n",
    "Zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Zip Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahathi Software Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nray Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koyo Bearings India Private Limited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWSSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. V. Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Watrana Traction Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hans Infomatic Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Global Product Compliance Consultancy Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Hindu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maratha Oil Refinery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name\n",
       "0                           Mahathi Software Pvt Ltd.\n",
       "1                                    Nray Enterprises\n",
       "2                Koyo Bearings India Private Limited.\n",
       "3                                               BWSSC\n",
       "4                                       A. V. Systems\n",
       "..                                                ...\n",
       "95                           Watrana Traction Company\n",
       "96                            Hans Infomatic Pvt Ltd.\n",
       "97  Global Product Compliance Consultancy Services...\n",
       "98                                          The Hindu\n",
       "99                               Maratha Oil Refinery\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "Account_name=accounts_data_df.loc[:, ['Name']]\n",
    "\n",
    "\n",
    "Account_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(\"C:/Users\\AnujSingh/OneDrive - Foetron Consultancy Services Pvt Ltd/Documents/Foetron/Coding/D365AccountsETL/anuj_100_freshales_31st August.csv\")]\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               Mahathi Software Pvt Ltd.\n",
      "1                        Nray Enterprises\n",
      "2    Koyo Bearings India Private Limited.\n",
      "3                                   Bwssc\n",
      "4                           A. V. Systems\n",
      "Name: Standardized Name, dtype: object\n",
      "File has been transferred successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the source CSV file\n",
    "source_file = os.path.join(\"anuj_100_freshales_31st August.csv\")\n",
    "data = pd.read_csv(source_file)\n",
    "\n",
    "# Process the data if needed (e.g., standardize names)\n",
    "def standardize_name(name):\n",
    "    # Capitalizes the account names\n",
    "    # does not: \n",
    "    #    - pvt to private \n",
    "    #    - beautiful soup and linkedin validation \n",
    "    #    - name correction from zauba or mca \n",
    "    return name.strip().title()\n",
    "\n",
    "data['Standardized Name'] = data['Name'].apply(standardize_name)\n",
    "print(data['Standardized Name'].head())\n",
    "\n",
    "# Save the processed data to the destination CSV file\n",
    "destination_file = os.path.join(\"transformed\", \"anuj_100_fs_to_d365_transformed v1.csv\")\n",
    "data.to_csv(destination_file, index=False)\n",
    "\n",
    "print(\"File has been transferred successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Standardized Zipcode\n",
      "0                 32819\n",
      "1                201301\n",
      "2                123501\n",
      "3                122002\n",
      "4                110020\n",
      "..                  ...\n",
      "95                 None\n",
      "96                 None\n",
      "97               560091\n",
      "98                 None\n",
      "99               400028\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnujSingh\\AppData\\Local\\Temp\\ipykernel_13444\\2852733207.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zip_codes['Standardized Zipcode'] = zip_codes['Zipcode'].apply(standardize_zip_code)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming accounts_data_df is your DataFrame and 'Zipcode' is the column name\n",
    "# Extract the 'Zipcode' column\n",
    "zip_codes = accounts_data_df[['Zipcode']]\n",
    "\n",
    "# Function to standardize ZIP codes\n",
    "def standardize_zip_code(zip_code):\n",
    "    if pd.isna(zip_code):\n",
    "        return None\n",
    "    \n",
    "    # Remove all non-numeric characters\n",
    "    cleaned_zip = re.sub(r'\\D', '', str(zip_code))\n",
    "    \n",
    "    # Standardize the format\n",
    "    if len(cleaned_zip) == 5:\n",
    "        return cleaned_zip  # 5-digit ZIP code\n",
    "    elif len(cleaned_zip) == 9:\n",
    "        return cleaned_zip[:5] + '-' + cleaned_zip[5:]  # Convert to 9-digit ZIP code (12345-6789)\n",
    "    else:\n",
    "        return cleaned_zip  # Return as is if not fitting the expected format\n",
    "\n",
    "# Apply the standardization function\n",
    "zip_codes['Standardized Zipcode'] = zip_codes['Zipcode'].apply(standardize_zip_code)\n",
    "\n",
    "# Optionally, drop the old 'Zipcode' column\n",
    "zip_codes = zip_codes.drop(columns=['Zipcode'])\n",
    "\n",
    "# Display the standardized ZIP codes\n",
    "print(zip_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser Fetch Automation  (Linkedin , Zauba Corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIN number is required!\n",
      "Error: Failed to fetch data, status code: 403\n",
      "No data found for the given CIN.\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from urllib.parse import quote_plus\n",
    "\n",
    "# def correct_company_name(name):\n",
    "#     # Basic example of name correction: strip leading/trailing whitespace and fix common typos\n",
    "#     corrected_name = name.strip()\n",
    "#     # Add more correction logic as needed\n",
    "#     return corrected_name\n",
    "\n",
    "# def scrape_mca_data(cin):\n",
    "#     try:\n",
    "#         # URL encode the CIN to handle special characters\n",
    "#         encoded_cin = quote_plus(cin)\n",
    "#         URL = f'https://www.mca.gov.in/mcafoportal/companySearch.do?searchType=company&searchCriteria={encoded_cin}'\n",
    "        \n",
    "#         response = requests.get(URL)\n",
    "#         if response.status_code != 200:\n",
    "#             raise Exception(f'Failed to fetch data, status code: {response.status_code}')\n",
    "        \n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "#         # Find and parse the relevant data\n",
    "#         company_data = {}\n",
    "#         company_name = soup.find('div', class_='companyName')\n",
    "#         if company_name:\n",
    "#             company_data['name'] = company_name.get_text(strip=True)\n",
    "        \n",
    "#         company_details = soup.find_all('div', class_='details')\n",
    "#         for detail in company_details:\n",
    "#             label = detail.find('span', class_='label').get_text(strip=True)\n",
    "#             value = detail.find('span', class_='value').get_text(strip=True)\n",
    "#             company_data[label] = value\n",
    "        \n",
    "#         return company_data\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f'Error: {str(e)}')\n",
    "#         return None\n",
    "\n",
    "\n",
    "# cin = input('Enter CIN number: ').strip().upper()\n",
    "# if not cin:\n",
    "#     print('CIN number is required!')\n",
    "\n",
    "\n",
    "# corrected_cin = correct_company_name(cin)\n",
    "# company_data = scrape_mca_data(corrected_cin)\n",
    "\n",
    "# if company_data:\n",
    "#     print('Company Data:', company_data)\n",
    "# else:\n",
    "#     print('No data found for the given CIN.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahathi Software Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nray Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koyo Bearings India Private Limited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWSSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. V. Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Watrana Traction Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hans Infomatic Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Global Product Compliance Consultancy Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Hindu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maratha Oil Refinery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name\n",
       "0                           Mahathi Software Pvt Ltd.\n",
       "1                                    Nray Enterprises\n",
       "2                Koyo Bearings India Private Limited.\n",
       "3                                               BWSSC\n",
       "4                                       A. V. Systems\n",
       "..                                                ...\n",
       "95                           Watrana Traction Company\n",
       "96                            Hans Infomatic Pvt Ltd.\n",
       "97  Global Product Compliance Consultancy Services...\n",
       "98                                          The Hindu\n",
       "99                               Maratha Oil Refinery\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "Account_name=accounts_data_df.loc[:, ['Name']]\n",
    "Account_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahathi Software Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nray Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koyo Bearings India Private Limited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWSSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. V. Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Watrana Traction Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hans Infomatic Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Global Product Compliance Consultancy Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Hindu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maratha Oil Refinery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name\n",
       "0                           Mahathi Software Pvt Ltd.\n",
       "1                                    Nray Enterprises\n",
       "2                Koyo Bearings India Private Limited.\n",
       "3                                               BWSSC\n",
       "4                                       A. V. Systems\n",
       "..                                                ...\n",
       "95                           Watrana Traction Company\n",
       "96                            Hans Infomatic Pvt Ltd.\n",
       "97  Global Product Compliance Consultancy Services...\n",
       "98                                          The Hindu\n",
       "99                               Maratha Oil Refinery\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"Destination/anuj_100_fs_to_d365_transformed v1.csv\")\n",
    "Account_name=accounts_data_df.loc[:, ['Name']]\n",
    "Account_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Mahathi Software Pvt Ltd. to Skip to main content\n",
      "Updating Nray Enterprises to Skip to main content\n",
      "Updating Koyo Bearings India Private Limited. to Skip to main content\n",
      "Updating BWSSC to Skip to main content\n",
      "Updating A. V. Systems to Skip to main content\n",
      "Updating Mansui Trading Pvt.Ltd. to Skip to main content\n",
      "Updating ACS Infotech Pvt. Ltd. to Skip to main content\n",
      "Updating Saigun Technologies Pvt. Ltd. / Empxtrack, Inc to Skip to main content\n",
      "Updating QVC Realty Co. Limited to Skip to main content\n",
      "Updating Light Ray Advisors - Elevation Capital to Skip to main content\n",
      "Updating Neco Industries Limited to Skip to main content\n",
      "Updating Holostik India Ltd. to Skip to main content\n",
      "Updating IPE Global Ltd to Skip to main content\n",
      "Updating Acidaes Solutions Private Limited (CRMNEXT) to Skip to main content\n",
      "Updating Parijat Industries India Pvt. Ltd to Skip to main content\n",
      "Updating Exzeo Software to Skip to main content\n",
      "Updating Safexpress Pvt Ltd to Skip to main content\n",
      "Updating Tiger Logistics India Limited to Skip to main content\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00998213+26163]\n\t(No symbol) [0x00929CC4]\n\t(No symbol) [0x008224C3]\n\t(No symbol) [0x007FE27B]\n\t(No symbol) [0x0089192F]\n\t(No symbol) [0x008A3F99]\n\t(No symbol) [0x0088AA56]\n\t(No symbol) [0x0085BE89]\n\t(No symbol) [0x0085C8CD]\n\tGetHandleVerifier [0x00C6D313+2996019]\n\tGetHandleVerifier [0x00CC1B89+3342249]\n\tGetHandleVerifier [0x00A27AEF+614159]\n\tGetHandleVerifier [0x00A2F17C+644508]\n\t(No symbol) [0x009327FD]\n\t(No symbol) [0x0092F6F8]\n\t(No symbol) [0x0092F895]\n\t(No symbol) [0x00921C16]\n\tBaseThreadInitThunk [0x772C7BA9+25]\n\tRtlInitializeExceptionChain [0x776BC10B+107]\n\tRtlClearBits [0x776BC08F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Loop through each company name in the CSV file\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, company \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(company_names):\n\u001b[1;32m---> 50\u001b[0m     details \u001b[38;5;241m=\u001b[39m \u001b[43msearch_zauba_corp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompany\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# If the correct company name is found, update it in the DataFrame\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect_Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot Found\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36msearch_zauba_corp\u001b[1;34m(company_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Wait for the page to load\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Parse the results page with BeautifulSoup\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_source\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Extract company details (company name, company status, CIN, etc.)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m details \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:455\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_PAGE_SOURCE\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00998213+26163]\n\t(No symbol) [0x00929CC4]\n\t(No symbol) [0x008224C3]\n\t(No symbol) [0x007FE27B]\n\t(No symbol) [0x0089192F]\n\t(No symbol) [0x008A3F99]\n\t(No symbol) [0x0088AA56]\n\t(No symbol) [0x0085BE89]\n\t(No symbol) [0x0085C8CD]\n\tGetHandleVerifier [0x00C6D313+2996019]\n\tGetHandleVerifier [0x00CC1B89+3342249]\n\tGetHandleVerifier [0x00A27AEF+614159]\n\tGetHandleVerifier [0x00A2F17C+644508]\n\t(No symbol) [0x009327FD]\n\t(No symbol) [0x0092F6F8]\n\t(No symbol) [0x0092F895]\n\t(No symbol) [0x00921C16]\n\tBaseThreadInitThunk [0x772C7BA9+25]\n\tRtlInitializeExceptionChain [0x776BC10B+107]\n\tRtlClearBits [0x776BC08F+191]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Load CSV file\n",
    "file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the company names are stored in a column named 'Name'\n",
    "company_names = df['Name']\n",
    "\n",
    "# Set up Selenium WebDriver using Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "def search_zauba_corp(company_name):\n",
    "    # Open ZaubaCorp website\n",
    "    driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "    # Find the search box and input the company name\n",
    "    search_box = driver.find_element(By.ID, \"searchid\")\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(company_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Parse the results page with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Extract company details (company name, company status, CIN, etc.)\n",
    "    details = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetching the correct company name as displayed on ZaubaCorp\n",
    "        correct_name = soup.find('a', href=True).text.strip()\n",
    "        details['Correct_Name'] = correct_name\n",
    "    except AttributeError:\n",
    "        details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Loop through each company name in the CSV file\n",
    "for i, company in enumerate(company_names):\n",
    "    details = search_zauba_corp(company)\n",
    "    \n",
    "    # If the correct company name is found, update it in the DataFrame\n",
    "    if details['Correct_Name'] != 'Not Found':\n",
    "        print(f\"Updating {company} to {details['Correct_Name']}\")\n",
    "        df.at[i, 'Name'] = details['Correct_Name']  # Update the company name with the corrected name\n",
    "\n",
    "# Save the updated DataFrame back to the CSV\n",
    "df.to_csv(file_path, index=False)  # Overwrite the original file with corrected names\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Company names updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZAUBA DATA UPADATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Nray Enterprises to RRAY9 ENTERPRISES LLP (Match Score: 81)\n",
      "Updating ACS Infotech Pvt. Ltd. to ACES INFOTECH PVT LTD (Match Score: 98)\n",
      "Updating QVC Realty Co. Limited to QVC REALTY CO. LIMITED (Match Score: 100)\n",
      "Updating Neco Industries Limited to NECO INDUSTRIES LIMITED (Match Score: 100)\n",
      "Updating Tiger Logistics India Limited to TIGER LOGISTICS (INDIA) LIMITED (Match Score: 100)\n",
      "Updating Alok Industries Private Limited to ALOX INDUSTRIES PRIVATE LIMITED (Match Score: 97)\n",
      "Updating S.Chand & Company Pvt Ltd to HARAKH CHAND SARAOGI & COMPANY PVT.LTD. (Match Score: 78)\n",
      "Updating Savannah Seeds Private Limited to SAVANNAH SEEDS PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Avantha Technologies Limited to AVANTHA TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating Mark Software Systems to MARK SOFTWARE SYSTEMS PRIVATE LIMITED (Match Score: 72)\n",
      "Updating FLOVEL Energy Private Limited to FLOVEL ENERGY PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Kapadia Associates Design LLP to KAPADIA ASSOCIATES DESIGN LLP (Match Score: 100)\n",
      "Updating SS Associates to DS & ASSOCIATES LLP (Match Score: 80)\n",
      "Updating KARL STORZ Endoscopy India Private Limited to KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Templatolio Technologies to TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED (Match Score: 75)\n",
      "Updating HealthFore Technologies Limited to HEALTHFORE TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating Quick Sort India Private Limited to QUICK SORT (INDIA) PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Competent Synergies Private Limited to COMPETENT SYNERGIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating SPAG Consultants Pvt Ltd. to SPAM ENGINEERING CONSULTANTS PVT. LTD. (Match Score: 77)\n",
      "Updating Network Advertising to NETWORK ADVERTISING PVT LTD (Match Score: 83)\n",
      "Updating Jindal SAW Limited to JINDAL SAW LIMITED (Match Score: 100)\n",
      "Updating Kalahanu Retail Venture Limited to KALAHANU RETAIL VENTURE PRIVATE LIMITED (Match Score: 89)\n",
      "Updating Grazitti Interactive to GRAZITTI INTERACTIVE LLP (Match Score: 91)\n",
      "Updating Madhusudan Auto Limited to MADHUSUDAN AUTO PRIVATE LIMITED (Match Score: 85)\n",
      "Updating YS Communications Pvt. Ltd. to M&PS COMMUNICATIONS PVT LTD (Match Score: 85)\n",
      "Company names updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import time\n",
    "# from bs4 import BeautifulSoup\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# # Load CSV file\n",
    "# file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # Assuming the company names are stored in a column named 'Name'\n",
    "# company_names = df['Name']\n",
    "\n",
    "# # company names - split - [0][1]match with zauba\n",
    "# # corporate limited \n",
    "# # private limited \n",
    "\n",
    "# # corner case \n",
    "# # Holding company \n",
    "# # seperate company out \n",
    "\n",
    "\n",
    "# # make seperate files - \n",
    "\n",
    "\n",
    "# # Set up Selenium WebDriver using Service\n",
    "# service = Service(ChromeDriverManager().install())\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# def search_zauba_corp(company_name):\n",
    "#     # Open ZaubaCorp website\n",
    "#     driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "#     # Find the search box and input the company name\n",
    "#     search_box = driver.find_element(By.ID, \"searchid\")\n",
    "#     search_box.clear()\n",
    "#     search_box.send_keys(company_name)\n",
    "#     search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "#     time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "#     # Parse the results page with BeautifulSoup\n",
    "#     soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "#     # Extract company details (company name, company status, CIN, etc.)\n",
    "#     details = {}\n",
    "    \n",
    "#     try:\n",
    "#         # Fetching the correct company name as displayed on ZaubaCorp\n",
    "#         search_results = soup.find_all('a', href=True)\n",
    "#         # Extracting all company names from the search results\n",
    "#         company_names_from_zauba = [result.text.strip() for result in search_results]\n",
    "        \n",
    "#         # Use fuzzy matching to find the closest match to the original company name\n",
    "#         if company_names_from_zauba:\n",
    "#             best_match, match_score = process.extractOne(company_name, company_names_from_zauba, scorer=fuzz.token_sort_ratio)\n",
    "#             details['Correct_Name'] = best_match if match_score > 70 else 'Not Found'\n",
    "#         else:\n",
    "#             details['Correct_Name'] = 'Not Found'\n",
    "#     except AttributeError:\n",
    "#         details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "#     return details\n",
    "\n",
    "# # Loop through each company name in the CSV file\n",
    "# # run for only 10\n",
    "# for i, company in enumerate(company_names):\n",
    "#     details = search_zauba_corp(company)\n",
    "    \n",
    "#     # If the correct company name is found, update it in the DataFrame\n",
    "#     if details['Correct_Name'] != 'Not Found':\n",
    "#         print(f\"Updating {company} to {details['Correct_Name']} (Match Score: {fuzz.token_sort_ratio(company, details['Correct_Name'])})\")\n",
    "#         df.at[i, 'Name'] = details['Correct_Name']  # Update the company name with the corrected name\n",
    "\n",
    "# # Save the updated DataFrame back to the CSV\n",
    "# df.to_csv(\"updated.csv\", index=False)  # Overwrite the original file with corrected names\n",
    "\n",
    "# # Close the Selenium driver\n",
    "# driver.quit()\n",
    "\n",
    "# print(\"Company names updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZAUBA UPDATE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating RRAY9 ENTERPRISES LLP to RRAY9 ENTERPRISES LLP (Match Score: 100)\n",
      "Updating ACES INFOTECH PVT LTD to ACES INFOTECH PVT LTD (Match Score: 100)\n",
      "Updating QVC REALTY CO. LIMITED to QVC REALTY CO. LIMITED (Match Score: 100)\n",
      "Updating NECO INDUSTRIES LIMITED to NECO INDUSTRIES LIMITED (Match Score: 100)\n",
      "Updating TIGER LOGISTICS (INDIA) LIMITED to TIGER LOGISTICS (INDIA) LIMITED (Match Score: 100)\n",
      "Updating ALOX INDUSTRIES PRIVATE LIMITED to ALOX INDUSTRIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating HARAKH CHAND SARAOGI & COMPANY PVT.LTD. to HARAKH CHAND SARAOGI & COMPANY PVT.LTD. (Match Score: 100)\n",
      "Updating SAVANNAH SEEDS PRIVATE LIMITED to SAVANNAH SEEDS PRIVATE LIMITED (Match Score: 100)\n",
      "Updating AVANTHA TECHNOLOGIES LIMITED to AVANTHA TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating MARK SOFTWARE SYSTEMS PRIVATE LIMITED to MARK SOFTWARE SYSTEMS PRIVATE LIMITED (Match Score: 100)\n",
      "Updating FLOVEL ENERGY PRIVATE LIMITED to FLOVEL ENERGY PRIVATE LIMITED (Match Score: 100)\n",
      "Updating KAPADIA ASSOCIATES DESIGN LLP to KAPADIA ASSOCIATES DESIGN LLP (Match Score: 100)\n",
      "Updating DS & ASSOCIATES LLP to DS & ASSOCIATES LLP (Match Score: 100)\n",
      "Updating KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED to KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED (Match Score: 100)\n",
      "Updating TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED to TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating HEALTHFORE TECHNOLOGIES LIMITED to HEALTHFORE TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating QUICK SORT (INDIA) PRIVATE LIMITED to QUICK SORT (INDIA) PRIVATE LIMITED (Match Score: 100)\n",
      "Updating COMPETENT SYNERGIES PRIVATE LIMITED to COMPETENT SYNERGIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating SPAM ENGINEERING CONSULTANTS PVT. LTD. to SPAM ENGINEERING CONSULTANTS PVT. LTD. (Match Score: 100)\n",
      "Updating NETWORK ADVERTISING PVT LTD to NETWORK ADVERTISING PVT LTD (Match Score: 100)\n",
      "Updating JINDAL SAW LIMITED to JINDAL SAW LIMITED (Match Score: 100)\n",
      "Updating KALAHANU RETAIL VENTURE PRIVATE LIMITED to KALAHANU RETAIL VENTURE PRIVATE LIMITED (Match Score: 100)\n",
      "Updating GRAZITTI INTERACTIVE LLP to GRAZITTI INTERACTIVE LLP (Match Score: 100)\n",
      "Updating MADHUSUDAN AUTO PRIVATE LIMITED to MADHUSUDAN AUTO PRIVATE LIMITED (Match Score: 100)\n",
      "Updating M&PS COMMUNICATIONS PVT LTD to M&PS COMMUNICATIONS PVT LTD (Match Score: 100)\n",
      "Company names updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "# Load CSV file\n",
    "file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define common terms to ignore\n",
    "ignore_terms = ['Limited', 'Private Limited', 'Pvt Ltd', 'Corp', 'LLC', 'Inc']\n",
    "\n",
    "# Function to clean and preprocess company names\n",
    "def preprocess_name(name):\n",
    "    # Convert to lowercase\n",
    "    name = name.lower()\n",
    "    # Remove terms from the ignore list\n",
    "    for term in ignore_terms:\n",
    "        name = re.sub(r'\\b' + re.escape(term.lower()) + r'\\b', '', name)\n",
    "    # Remove extra spaces and return the cleaned name\n",
    "    return ' '.join(name.split())\n",
    "\n",
    "# Preprocess company names in DataFrame\n",
    "df['Processed_Name'] = df['Name'].apply(preprocess_name)\n",
    "\n",
    "# Set up Selenium WebDriver using Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "def search_zauba_corp(company_name):\n",
    "    # Open ZaubaCorp website\n",
    "    driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "    # Find the search box and input the company name\n",
    "    search_box = driver.find_element(By.ID, \"searchid\")\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(company_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Parse the results page with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Extract company details (company name, company status, CIN, etc.)\n",
    "    details = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetching the correct company name as displayed on ZaubaCorp\n",
    "        search_results = soup.find_all('a', href=True)\n",
    "        # Extracting all company names from the search results\n",
    "        company_names_from_zauba = [result.text.strip() for result in search_results]\n",
    "        \n",
    "        # Use fuzzy matching to find the closest match to the original company name\n",
    "        if company_names_from_zauba:\n",
    "            best_match, match_score = process.extractOne(company_name, company_names_from_zauba, scorer=fuzz.token_sort_ratio)\n",
    "            details['Correct_Name'] = best_match if match_score > 70 else 'Not Found'\n",
    "        else:\n",
    "            details['Correct_Name'] = 'Not Found'\n",
    "    except AttributeError:\n",
    "        details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Separate DataFrames for different cases\n",
    "df_corrected = pd.DataFrame(columns=['Original_Name', 'Correct_Name'])\n",
    "df_not_found = pd.DataFrame(columns=['Original_Name'])\n",
    "df_holding_company = pd.DataFrame(columns=['Original_Name'])\n",
    "df_separate_company = pd.DataFrame(columns=['Original_Name'])\n",
    "\n",
    "# Loop through each company name in the CSV file\n",
    "for i, row in df.iterrows():\n",
    "    company = row['Name']\n",
    "    details = search_zauba_corp(company)\n",
    "    \n",
    "    # Handle different cases\n",
    "    if details['Correct_Name'] != 'Not Found':\n",
    "        corrected_name = details['Correct_Name']\n",
    "        print(f\"Updating {company} to {corrected_name} (Match Score: {fuzz.token_sort_ratio(company, corrected_name)})\")\n",
    "        df_corrected = pd.concat([df_corrected, pd.DataFrame({'Original_Name': [company], 'Correct_Name': [corrected_name]})], ignore_index=True)\n",
    "    else:\n",
    "        # Check for corner cases\n",
    "        if 'holding company' in company.lower():\n",
    "            df_holding_company = pd.concat([df_holding_company, pd.DataFrame({'Original_Name': [company]})], ignore_index=True)\n",
    "        elif 'separate company' in company.lower():\n",
    "            df_separate_company = pd.concat([df_separate_company, pd.DataFrame({'Original_Name': [company]})], ignore_index=True)\n",
    "        else:\n",
    "            df_not_found = pd.concat([df_not_found, pd.DataFrame({'Original_Name': [company]})], ignore_index=True)\n",
    "\n",
    "# Save DataFrames to separate CSV files\n",
    "df_corrected.to_csv('corrected_company_names.csv', index=False)\n",
    "df_not_found.to_csv('not_found_company_names.csv', index=False)\n",
    "df_holding_company.to_csv('holding_company_names.csv', index=False)\n",
    "df_separate_company.to_csv('separate_company_names.csv', index=False)\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Company names updated successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
