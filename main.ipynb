{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>098739 30018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'+91-11-26382324'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>'+91-9740000662'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Phone\n",
       "0                 NaN\n",
       "1        098739 30018\n",
       "2                 NaN\n",
       "3                 NaN\n",
       "4   '+91-11-26382324'\n",
       "..                ...\n",
       "95                NaN\n",
       "96                NaN\n",
       "97   '+91-9740000662'\n",
       "98                NaN\n",
       "99                NaN\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "phone_numbers=accounts_data_df.loc[:, ['Phone']]\n",
    "phone_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Phone Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Standardized Phone\n",
      "0                None\n",
      "1      +91 9873930018\n",
      "2                None\n",
      "3                None\n",
      "4        911126382324\n",
      "..                ...\n",
      "95               None\n",
      "96               None\n",
      "97       919740000662\n",
      "98               None\n",
      "99               None\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to clean phone numbers\n",
    "def standardize_phone_number(phone):\n",
    "    if pd.isna(phone):\n",
    "        return None\n",
    "    \n",
    "    # Remove all non-numeric characters\n",
    "    cleaned_phone = re.sub(r'\\D', '', phone)\n",
    "    \n",
    "    # Ensure the phone number is in the format you want\n",
    "    # For example, assuming you want international format: +<country_code> <phone_number>\n",
    "    if len(cleaned_phone) == 10:\n",
    "        return '+91 ' + cleaned_phone  # Assuming +91 is the country code\n",
    "    elif len(cleaned_phone) == 11 and cleaned_phone.startswith('0'):\n",
    "        return '+91 ' + cleaned_phone[1:]  # Removing leading zero for the country code\n",
    "    else:\n",
    "        return cleaned_phone\n",
    "\n",
    "# Apply the function to the 'Phone' column\n",
    "phone_numbers['Standardized Phone'] = phone_numbers['Phone'].apply(standardize_phone_number)\n",
    "\n",
    "# Remove the original column if no longer needed\n",
    "phone_numbers = phone_numbers.drop(columns=['Phone'])\n",
    "\n",
    "# Display the result\n",
    "print(phone_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Standardized Phone\n",
      "0                None\n",
      "1      +91 9873930018\n",
      "2                None\n",
      "3                None\n",
      "4       +911126382324\n",
      "..                ...\n",
      "95               None\n",
      "96               None\n",
      "97      +919740000662\n",
      "98               None\n",
      "99               None\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnujSingh\\AppData\\Local\\Temp\\ipykernel_13444\\4013032854.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phone_numbers['Standardized Phone'] = phone_numbers['Phone'].apply(standardize_phone_number)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the 'Phone' column\n",
    "phone_numbers = accounts_data_df[['Phone']]\n",
    "\n",
    "# Function to standardize phone numbers\n",
    "def standardize_phone_number(phone):\n",
    "    if pd.isna(phone):\n",
    "        return None\n",
    "    \n",
    "    # Remove all non-numeric characters\n",
    "    cleaned_phone = re.sub(r'\\D', '', phone)\n",
    "    \n",
    "    # Standardize to international format\n",
    "    if len(cleaned_phone) == 10:\n",
    "        return '+91 ' + cleaned_phone  # Assuming +91 is the country code\n",
    "    elif len(cleaned_phone) == 11 and cleaned_phone.startswith('0'):\n",
    "        return '+91 ' + cleaned_phone[1:]  # Removing leading zero for the country code\n",
    "    elif len(cleaned_phone) == 12 and cleaned_phone.startswith('91'):\n",
    "        return '+' + cleaned_phone  # Already in international format, just add '+'\n",
    "    else:\n",
    "        return cleaned_phone  # Return as is if not fitting expected formats\n",
    "\n",
    "# Apply the standardization function\n",
    "phone_numbers['Standardized Phone'] = phone_numbers['Phone'].apply(standardize_phone_number)\n",
    "\n",
    "# Optionally, drop the old 'Phone' column\n",
    "phone_numbers = phone_numbers.drop(columns=['Phone'])\n",
    "\n",
    "# Display the standardized phone numbers\n",
    "print(phone_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>560091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>400028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zipcode\n",
       "0    32819\n",
       "1   201301\n",
       "2   123501\n",
       "3   122002\n",
       "4   110020\n",
       "..     ...\n",
       "95     NaN\n",
       "96     NaN\n",
       "97  560091\n",
       "98     NaN\n",
       "99  400028\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "Zipcode=accounts_data_df.loc[:, ['Zipcode']]\n",
    "\n",
    "\n",
    "Zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Zip Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'anuj_100_freshales_31st August.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accounts_data_df\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manuj_100_freshales_31st August.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m Account_name\u001b[38;5;241m=\u001b[39maccounts_data_df\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m Account_name\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'anuj_100_freshales_31st August.csv'"
     ]
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "Account_name=accounts_data_df.loc[:, ['Name']]\n",
    "\n",
    "\n",
    "Account_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               Mahathi Software Pvt Ltd.\n",
      "1                        Nray Enterprises\n",
      "2    Koyo Bearings India Private Limited.\n",
      "3                                   Bwssc\n",
      "4                           A. V. Systems\n",
      "Name: Standardized Name, dtype: object\n",
      "File has been transferred successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the source CSV file\n",
    "source_file = os.path.join(\"anuj_100_freshales_31st August.csv\")\n",
    "data = pd.read_csv(source_file)\n",
    "\n",
    "# Process the data if needed (e.g., standardize names)\n",
    "def standardize_name(name):\n",
    "    # Capitalizes the account names\n",
    "    # does not: \n",
    "    #    - pvt to private \n",
    "    #    - beautiful soup and linkedin validation \n",
    "    #    - name correction from zauba or mca \n",
    "    return name.strip().title()\n",
    "\n",
    "data['Standardized Name'] = data['Name'].apply(standardize_name)\n",
    "print(data['Standardized Name'].head())\n",
    "\n",
    "# Save the processed data to the destination CSV file\n",
    "destination_file = os.path.join(\"transformed\", \"anuj_100_fs_to_d365_transformed v1.csv\")\n",
    "data.to_csv(destination_file, index=False)\n",
    "\n",
    "print(\"File has been transferred successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Standardized Zipcode\n",
      "0                 32819\n",
      "1                201301\n",
      "2                123501\n",
      "3                122002\n",
      "4                110020\n",
      "..                  ...\n",
      "95                 None\n",
      "96                 None\n",
      "97               560091\n",
      "98                 None\n",
      "99               400028\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnujSingh\\AppData\\Local\\Temp\\ipykernel_13444\\2852733207.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zip_codes['Standardized Zipcode'] = zip_codes['Zipcode'].apply(standardize_zip_code)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming accounts_data_df is your DataFrame and 'Zipcode' is the column name\n",
    "# Extract the 'Zipcode' column\n",
    "zip_codes = accounts_data_df[['Zipcode']]\n",
    "\n",
    "# Function to standardize ZIP codes\n",
    "def standardize_zip_code(zip_code):\n",
    "    if pd.isna(zip_code):\n",
    "        return None\n",
    "    \n",
    "    # Remove all non-numeric characters\n",
    "    cleaned_zip = re.sub(r'\\D', '', str(zip_code))\n",
    "    \n",
    "    # Standardize the format\n",
    "    if len(cleaned_zip) == 5:\n",
    "        return cleaned_zip  # 5-digit ZIP code\n",
    "    elif len(cleaned_zip) == 9:\n",
    "        return cleaned_zip[:5] + '-' + cleaned_zip[5:]  # Convert to 9-digit ZIP code (12345-6789)\n",
    "    else:\n",
    "        return cleaned_zip  # Return as is if not fitting the expected format\n",
    "\n",
    "# Apply the standardization function\n",
    "zip_codes['Standardized Zipcode'] = zip_codes['Zipcode'].apply(standardize_zip_code)\n",
    "\n",
    "# Optionally, drop the old 'Zipcode' column\n",
    "zip_codes = zip_codes.drop(columns=['Zipcode'])\n",
    "\n",
    "# Display the standardized ZIP codes\n",
    "print(zip_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser Fetch Automation  (Linkedin , Zauba Corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIN number is required!\n",
      "Error: Failed to fetch data, status code: 403\n",
      "No data found for the given CIN.\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from urllib.parse import quote_plus\n",
    "\n",
    "# def correct_company_name(name):\n",
    "#     # Basic example of name correction: strip leading/trailing whitespace and fix common typos\n",
    "#     corrected_name = name.strip()\n",
    "#     # Add more correction logic as needed\n",
    "#     return corrected_name\n",
    "\n",
    "# def scrape_mca_data(cin):\n",
    "#     try:\n",
    "#         # URL encode the CIN to handle special characters\n",
    "#         encoded_cin = quote_plus(cin)\n",
    "#         URL = f'https://www.mca.gov.in/mcafoportal/companySearch.do?searchType=company&searchCriteria={encoded_cin}'\n",
    "        \n",
    "#         response = requests.get(URL)\n",
    "#         if response.status_code != 200:\n",
    "#             raise Exception(f'Failed to fetch data, status code: {response.status_code}')\n",
    "        \n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "#         # Find and parse the relevant data\n",
    "#         company_data = {}\n",
    "#         company_name = soup.find('div', class_='companyName')\n",
    "#         if company_name:\n",
    "#             company_data['name'] = company_name.get_text(strip=True)\n",
    "        \n",
    "#         company_details = soup.find_all('div', class_='details')\n",
    "#         for detail in company_details:\n",
    "#             label = detail.find('span', class_='label').get_text(strip=True)\n",
    "#             value = detail.find('span', class_='value').get_text(strip=True)\n",
    "#             company_data[label] = value\n",
    "        \n",
    "#         return company_data\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f'Error: {str(e)}')\n",
    "#         return None\n",
    "\n",
    "\n",
    "# cin = input('Enter CIN number: ').strip().upper()\n",
    "# if not cin:\n",
    "#     print('CIN number is required!')\n",
    "\n",
    "\n",
    "# corrected_cin = correct_company_name(cin)\n",
    "# company_data = scrape_mca_data(corrected_cin)\n",
    "\n",
    "# if company_data:\n",
    "#     print('Company Data:', company_data)\n",
    "# else:\n",
    "#     print('No data found for the given CIN.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahathi Software Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nray Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koyo Bearings India Private Limited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWSSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. V. Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Watrana Traction Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hans Infomatic Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Global Product Compliance Consultancy Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Hindu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maratha Oil Refinery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name\n",
       "0                           Mahathi Software Pvt Ltd.\n",
       "1                                    Nray Enterprises\n",
       "2                Koyo Bearings India Private Limited.\n",
       "3                                               BWSSC\n",
       "4                                       A. V. Systems\n",
       "..                                                ...\n",
       "95                           Watrana Traction Company\n",
       "96                            Hans Infomatic Pvt Ltd.\n",
       "97  Global Product Compliance Consultancy Services...\n",
       "98                                          The Hindu\n",
       "99                               Maratha Oil Refinery\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"anuj_100_freshales_31st August.csv\")\n",
    "Account_name=accounts_data_df.loc[:, ['Name']]\n",
    "Account_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahathi Software Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nray Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koyo Bearings India Private Limited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWSSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. V. Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Watrana Traction Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hans Infomatic Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Global Product Compliance Consultancy Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Hindu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maratha Oil Refinery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name\n",
       "0                           Mahathi Software Pvt Ltd.\n",
       "1                                    Nray Enterprises\n",
       "2                Koyo Bearings India Private Limited.\n",
       "3                                               BWSSC\n",
       "4                                       A. V. Systems\n",
       "..                                                ...\n",
       "95                           Watrana Traction Company\n",
       "96                            Hans Infomatic Pvt Ltd.\n",
       "97  Global Product Compliance Consultancy Services...\n",
       "98                                          The Hindu\n",
       "99                               Maratha Oil Refinery\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"Destination/anuj_100_fs_to_d365_transformed v1.csv\")\n",
    "Account_name=accounts_data_df.loc[:, ['Name']]\n",
    "Account_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Mahathi Software Pvt Ltd. to Skip to main content\n",
      "Updating Nray Enterprises to Skip to main content\n",
      "Updating Koyo Bearings India Private Limited. to Skip to main content\n",
      "Updating BWSSC to Skip to main content\n",
      "Updating A. V. Systems to Skip to main content\n",
      "Updating Mansui Trading Pvt.Ltd. to Skip to main content\n",
      "Updating ACS Infotech Pvt. Ltd. to Skip to main content\n",
      "Updating Saigun Technologies Pvt. Ltd. / Empxtrack, Inc to Skip to main content\n",
      "Updating QVC Realty Co. Limited to Skip to main content\n",
      "Updating Light Ray Advisors - Elevation Capital to Skip to main content\n",
      "Updating Neco Industries Limited to Skip to main content\n",
      "Updating Holostik India Ltd. to Skip to main content\n",
      "Updating IPE Global Ltd to Skip to main content\n",
      "Updating Acidaes Solutions Private Limited (CRMNEXT) to Skip to main content\n",
      "Updating Parijat Industries India Pvt. Ltd to Skip to main content\n",
      "Updating Exzeo Software to Skip to main content\n",
      "Updating Safexpress Pvt Ltd to Skip to main content\n",
      "Updating Tiger Logistics India Limited to Skip to main content\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00998213+26163]\n\t(No symbol) [0x00929CC4]\n\t(No symbol) [0x008224C3]\n\t(No symbol) [0x007FE27B]\n\t(No symbol) [0x0089192F]\n\t(No symbol) [0x008A3F99]\n\t(No symbol) [0x0088AA56]\n\t(No symbol) [0x0085BE89]\n\t(No symbol) [0x0085C8CD]\n\tGetHandleVerifier [0x00C6D313+2996019]\n\tGetHandleVerifier [0x00CC1B89+3342249]\n\tGetHandleVerifier [0x00A27AEF+614159]\n\tGetHandleVerifier [0x00A2F17C+644508]\n\t(No symbol) [0x009327FD]\n\t(No symbol) [0x0092F6F8]\n\t(No symbol) [0x0092F895]\n\t(No symbol) [0x00921C16]\n\tBaseThreadInitThunk [0x772C7BA9+25]\n\tRtlInitializeExceptionChain [0x776BC10B+107]\n\tRtlClearBits [0x776BC08F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Loop through each company name in the CSV file\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, company \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(company_names):\n\u001b[1;32m---> 50\u001b[0m     details \u001b[38;5;241m=\u001b[39m \u001b[43msearch_zauba_corp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompany\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# If the correct company name is found, update it in the DataFrame\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect_Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot Found\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36msearch_zauba_corp\u001b[1;34m(company_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Wait for the page to load\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Parse the results page with BeautifulSoup\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_source\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Extract company details (company name, company status, CIN, etc.)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m details \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:455\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_PAGE_SOURCE\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00998213+26163]\n\t(No symbol) [0x00929CC4]\n\t(No symbol) [0x008224C3]\n\t(No symbol) [0x007FE27B]\n\t(No symbol) [0x0089192F]\n\t(No symbol) [0x008A3F99]\n\t(No symbol) [0x0088AA56]\n\t(No symbol) [0x0085BE89]\n\t(No symbol) [0x0085C8CD]\n\tGetHandleVerifier [0x00C6D313+2996019]\n\tGetHandleVerifier [0x00CC1B89+3342249]\n\tGetHandleVerifier [0x00A27AEF+614159]\n\tGetHandleVerifier [0x00A2F17C+644508]\n\t(No symbol) [0x009327FD]\n\t(No symbol) [0x0092F6F8]\n\t(No symbol) [0x0092F895]\n\t(No symbol) [0x00921C16]\n\tBaseThreadInitThunk [0x772C7BA9+25]\n\tRtlInitializeExceptionChain [0x776BC10B+107]\n\tRtlClearBits [0x776BC08F+191]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Load CSV file\n",
    "file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the company names are stored in a column named 'Name'\n",
    "company_names = df['Name']\n",
    "\n",
    "# Set up Selenium WebDriver using Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "def search_zauba_corp(company_name):\n",
    "    # Open ZaubaCorp website\n",
    "    driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "    # Find the search box and input the company name\n",
    "    search_box = driver.find_element(By.ID, \"searchid\")\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(company_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Parse the results page with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Extract company details (company name, company status, CIN, etc.)\n",
    "    details = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetching the correct company name as displayed on ZaubaCorp\n",
    "        correct_name = soup.find('a', href=True).text.strip()\n",
    "        details['Correct_Name'] = correct_name\n",
    "    except AttributeError:\n",
    "        details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Loop through each company name in the CSV file\n",
    "for i, company in enumerate(company_names):\n",
    "    details = search_zauba_corp(company)\n",
    "    \n",
    "    # If the correct company name is found, update it in the DataFrame\n",
    "    if details['Correct_Name'] != 'Not Found':\n",
    "        print(f\"Updating {company} to {details['Correct_Name']}\")\n",
    "        df.at[i, 'Name'] = details['Correct_Name']  # Update the company name with the corrected name\n",
    "\n",
    "# Save the updated DataFrame back to the CSV\n",
    "df.to_csv(file_path, index=False)  # Overwrite the original file with corrected names\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Company names updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZAUBA DATA UPADATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Nray Enterprises to RRAY9 ENTERPRISES LLP (Match Score: 81)\n",
      "Updating ACS Infotech Pvt. Ltd. to ACES INFOTECH PVT LTD (Match Score: 98)\n",
      "Updating QVC Realty Co. Limited to QVC REALTY CO. LIMITED (Match Score: 100)\n",
      "Updating Neco Industries Limited to NECO INDUSTRIES LIMITED (Match Score: 100)\n",
      "Updating Tiger Logistics India Limited to TIGER LOGISTICS (INDIA) LIMITED (Match Score: 100)\n",
      "Updating Alok Industries Private Limited to ALOX INDUSTRIES PRIVATE LIMITED (Match Score: 97)\n",
      "Updating S.Chand & Company Pvt Ltd to HARAKH CHAND SARAOGI & COMPANY PVT.LTD. (Match Score: 78)\n",
      "Updating Savannah Seeds Private Limited to SAVANNAH SEEDS PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Avantha Technologies Limited to AVANTHA TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating Mark Software Systems to MARK SOFTWARE SYSTEMS PRIVATE LIMITED (Match Score: 72)\n",
      "Updating FLOVEL Energy Private Limited to FLOVEL ENERGY PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Kapadia Associates Design LLP to KAPADIA ASSOCIATES DESIGN LLP (Match Score: 100)\n",
      "Updating SS Associates to DS & ASSOCIATES LLP (Match Score: 80)\n",
      "Updating KARL STORZ Endoscopy India Private Limited to KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Templatolio Technologies to TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED (Match Score: 75)\n",
      "Updating HealthFore Technologies Limited to HEALTHFORE TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating Quick Sort India Private Limited to QUICK SORT (INDIA) PRIVATE LIMITED (Match Score: 100)\n",
      "Updating Competent Synergies Private Limited to COMPETENT SYNERGIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating SPAG Consultants Pvt Ltd. to SPAM ENGINEERING CONSULTANTS PVT. LTD. (Match Score: 77)\n",
      "Updating Network Advertising to NETWORK ADVERTISING PVT LTD (Match Score: 83)\n",
      "Updating Jindal SAW Limited to JINDAL SAW LIMITED (Match Score: 100)\n",
      "Updating Kalahanu Retail Venture Limited to KALAHANU RETAIL VENTURE PRIVATE LIMITED (Match Score: 89)\n",
      "Updating Grazitti Interactive to GRAZITTI INTERACTIVE LLP (Match Score: 91)\n",
      "Updating Madhusudan Auto Limited to MADHUSUDAN AUTO PRIVATE LIMITED (Match Score: 85)\n",
      "Updating YS Communications Pvt. Ltd. to M&PS COMMUNICATIONS PVT LTD (Match Score: 85)\n",
      "Company names updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import time\n",
    "# from bs4 import BeautifulSoup\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# # Load CSV file\n",
    "# file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # Assuming the company names are stored in a column named 'Name'\n",
    "# company_names = df['Name']\n",
    "\n",
    "# # company names - split - [0][1]match with zauba\n",
    "# # corporate limited \n",
    "# # private limited \n",
    "\n",
    "# # corner case \n",
    "# # Holding company \n",
    "# # seperate company out \n",
    "\n",
    "\n",
    "# # make seperate files - \n",
    "\n",
    "\n",
    "# # Set up Selenium WebDriver using Service\n",
    "# service = Service(ChromeDriverManager().install())\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# def search_zauba_corp(company_name):\n",
    "#     # Open ZaubaCorp website\n",
    "#     driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "#     # Find the search box and input the company name\n",
    "#     search_box = driver.find_element(By.ID, \"searchid\")\n",
    "#     search_box.clear()\n",
    "#     search_box.send_keys(company_name)\n",
    "#     search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "#     time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "#     # Parse the results page with BeautifulSoup\n",
    "#     soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "#     # Extract company details (company name, company status, CIN, etc.)\n",
    "#     details = {}\n",
    "    \n",
    "#     try:\n",
    "#         # Fetching the correct company name as displayed on ZaubaCorp\n",
    "#         search_results = soup.find_all('a', href=True)\n",
    "#         # Extracting all company names from the search results\n",
    "#         company_names_from_zauba = [result.text.strip() for result in search_results]\n",
    "        \n",
    "#         # Use fuzzy matching to find the closest match to the original company name\n",
    "#         if company_names_from_zauba:\n",
    "#             best_match, match_score = process.extractOne(company_name, company_names_from_zauba, scorer=fuzz.token_sort_ratio)\n",
    "#             details['Correct_Name'] = best_match if match_score > 70 else 'Not Found'\n",
    "#         else:\n",
    "#             details['Correct_Name'] = 'Not Found'\n",
    "#     except AttributeError:\n",
    "#         details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "#     return details\n",
    "\n",
    "# # Loop through each company name in the CSV file\n",
    "# # run for only 10\n",
    "# for i, company in enumerate(company_names):\n",
    "#     details = search_zauba_corp(company)\n",
    "    \n",
    "#     # If the correct company name is found, update it in the DataFrame\n",
    "#     if details['Correct_Name'] != 'Not Found':\n",
    "#         print(f\"Updating {company} to {details['Correct_Name']} (Match Score: {fuzz.token_sort_ratio(company, details['Correct_Name'])})\")\n",
    "#         df.at[i, 'Name'] = details['Correct_Name']  # Update the company name with the corrected name\n",
    "\n",
    "# # Save the updated DataFrame back to the CSV\n",
    "# df.to_csv(\"updated.csv\", index=False)  # Overwrite the original file with corrected names\n",
    "\n",
    "# # Close the Selenium driver\n",
    "# driver.quit()\n",
    "\n",
    "# print(\"Company names updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZAUBA UPDATE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating RRAY9 ENTERPRISES LLP to RRAY9 ENTERPRISES LLP (Match Score: 100)\n",
      "Updating ACES INFOTECH PVT LTD to ACES INFOTECH PVT LTD (Match Score: 100)\n",
      "Updating QVC REALTY CO. LIMITED to QVC REALTY CO. LIMITED (Match Score: 100)\n",
      "Updating NECO INDUSTRIES LIMITED to NECO INDUSTRIES LIMITED (Match Score: 100)\n",
      "Updating TIGER LOGISTICS (INDIA) LIMITED to TIGER LOGISTICS (INDIA) LIMITED (Match Score: 100)\n",
      "Updating ALOX INDUSTRIES PRIVATE LIMITED to ALOX INDUSTRIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating HARAKH CHAND SARAOGI & COMPANY PVT.LTD. to HARAKH CHAND SARAOGI & COMPANY PVT.LTD. (Match Score: 100)\n",
      "Updating SAVANNAH SEEDS PRIVATE LIMITED to SAVANNAH SEEDS PRIVATE LIMITED (Match Score: 100)\n",
      "Updating AVANTHA TECHNOLOGIES LIMITED to AVANTHA TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating MARK SOFTWARE SYSTEMS PRIVATE LIMITED to MARK SOFTWARE SYSTEMS PRIVATE LIMITED (Match Score: 100)\n",
      "Updating FLOVEL ENERGY PRIVATE LIMITED to FLOVEL ENERGY PRIVATE LIMITED (Match Score: 100)\n",
      "Updating KAPADIA ASSOCIATES DESIGN LLP to KAPADIA ASSOCIATES DESIGN LLP (Match Score: 100)\n",
      "Updating DS & ASSOCIATES LLP to DS & ASSOCIATES LLP (Match Score: 100)\n",
      "Updating KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED to KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED (Match Score: 100)\n",
      "Updating TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED to TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating HEALTHFORE TECHNOLOGIES LIMITED to HEALTHFORE TECHNOLOGIES LIMITED (Match Score: 100)\n",
      "Updating QUICK SORT (INDIA) PRIVATE LIMITED to QUICK SORT (INDIA) PRIVATE LIMITED (Match Score: 100)\n",
      "Updating COMPETENT SYNERGIES PRIVATE LIMITED to COMPETENT SYNERGIES PRIVATE LIMITED (Match Score: 100)\n",
      "Updating SPAM ENGINEERING CONSULTANTS PVT. LTD. to SPAM ENGINEERING CONSULTANTS PVT. LTD. (Match Score: 100)\n",
      "Updating NETWORK ADVERTISING PVT LTD to NETWORK ADVERTISING PVT LTD (Match Score: 100)\n",
      "Updating JINDAL SAW LIMITED to JINDAL SAW LIMITED (Match Score: 100)\n",
      "Updating KALAHANU RETAIL VENTURE PRIVATE LIMITED to KALAHANU RETAIL VENTURE PRIVATE LIMITED (Match Score: 100)\n",
      "Updating GRAZITTI INTERACTIVE LLP to GRAZITTI INTERACTIVE LLP (Match Score: 100)\n",
      "Updating MADHUSUDAN AUTO PRIVATE LIMITED to MADHUSUDAN AUTO PRIVATE LIMITED (Match Score: 100)\n",
      "Updating M&PS COMMUNICATIONS PVT LTD to M&PS COMMUNICATIONS PVT LTD (Match Score: 100)\n",
      "Company names updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "# Load CSV file\n",
    "file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define common terms to ignore\n",
    "ignore_terms = ['Limited', 'Private Limited', 'Pvt Ltd', 'Corp', 'LLC', 'Inc']\n",
    "\n",
    "# Function to clean and preprocess company names\n",
    "def preprocess_name(name):\n",
    "    # Convert to lowercase\n",
    "    name = name.lower()\n",
    "    # Remove terms from the ignore list\n",
    "    for term in ignore_terms:\n",
    "        name = re.sub(r'\\b' + re.escape(term.lower()) + r'\\b', '', name)\n",
    "    # Remove extra spaces and return the cleaned name\n",
    "    return ' '.join(name.split())\n",
    "\n",
    "# Preprocess company names in DataFrame\n",
    "df['Processed_Name'] = df['Name'].apply(preprocess_name)\n",
    "\n",
    "# Set up Selenium WebDriver using Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "def search_zauba_corp(company_name):\n",
    "    # Open ZaubaCorp website\n",
    "    driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "    # Find the search box and input the company name\n",
    "    search_box = driver.find_element(By.ID, \"searchid\")\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(company_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Parse the results page with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Extract company details (company name, company status, CIN, etc.)\n",
    "    details = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetching the correct company name as displayed on ZaubaCorp\n",
    "        search_results = soup.find_all('a', href=True)\n",
    "        # Extracting all company names from the search results\n",
    "        company_names_from_zauba = [result.text.strip() for result in search_results]\n",
    "        \n",
    "        # Use fuzzy matching to find the closest match to the original company name\n",
    "        if company_names_from_zauba:\n",
    "            best_match, match_score = process.extractOne(company_name, company_names_from_zauba, scorer=fuzz.token_sort_ratio)\n",
    "            details['Correct_Name'] = best_match if match_score > 70 else 'Not Found'\n",
    "        else:\n",
    "            details['Correct_Name'] = 'Not Found'\n",
    "    except AttributeError:\n",
    "        details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Separate DataFrames for different cases\n",
    "df_corrected = pd.DataFrame(columns=['Original_Name', 'Correct_Name'])\n",
    "df_not_found = pd.DataFrame(columns=['Original_Name'])\n",
    "df_holding_company = pd.DataFrame(columns=['Original_Name'])\n",
    "df_separate_company = pd.DataFrame(columns=['Original_Name'])\n",
    "\n",
    "# Loop through each company name in the CSV file\n",
    "for i, row in df.iterrows():\n",
    "    company = row['Name']\n",
    "    details = search_zauba_corp(company)\n",
    "    \n",
    "    # Handle different cases\n",
    "    if details['Correct_Name'] != 'Not Found':\n",
    "        corrected_name = details['Correct_Name']\n",
    "        print(f\"Updating {company} to {corrected_name} (Match Score: {fuzz.token_sort_ratio(company, corrected_name)})\")\n",
    "        df_corrected = pd.concat([df_corrected, pd.DataFrame({'Original_Name': [company], 'Correct_Name': [corrected_name]})], ignore_index=True)\n",
    "    else:\n",
    "        # Check for corner cases\n",
    "        if 'holding company' in company.lower():\n",
    "            df_holding_company = pd.concat([df_holding_company, pd.DataFrame({'Original_Name': [company]})], ignore_index=True)\n",
    "        elif 'separate company' in company.lower():\n",
    "            df_separate_company = pd.concat([df_separate_company, pd.DataFrame({'Original_Name': [company]})], ignore_index=True)\n",
    "        else:\n",
    "            df_not_found = pd.concat([df_not_found, pd.DataFrame({'Original_Name': [company]})], ignore_index=True)\n",
    "\n",
    "# Save DataFrames to separate CSV files\n",
    "df_corrected.to_csv('corrected_company_names.csv', index=False)\n",
    "df_not_found.to_csv('not_found_company_names.csv', index=False)\n",
    "df_holding_company.to_csv('holding_company_names.csv', index=False)\n",
    "df_separate_company.to_csv('separate_company_names.csv', index=False)\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Company names updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANUJ TRANSFORMED DATA UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahathi Software Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nray Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koyo Bearings India Private Limited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWSSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. V. Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Watrana Traction Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hans Infomatic Pvt Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Global Product Compliance Consultancy Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Hindu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maratha Oil Refinery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name\n",
       "0                           Mahathi Software Pvt Ltd.\n",
       "1                                    Nray Enterprises\n",
       "2                Koyo Bearings India Private Limited.\n",
       "3                                               BWSSC\n",
       "4                                       A. V. Systems\n",
       "..                                                ...\n",
       "95                           Watrana Traction Company\n",
       "96                            Hans Infomatic Pvt Ltd.\n",
       "97  Global Product Compliance Consultancy Services...\n",
       "98                                          The Hindu\n",
       "99                               Maratha Oil Refinery\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_data_df= pd.read_csv(\"Destination/anuj_100_fs_to_d365_transformed.csv\")\n",
    "Account_name=accounts_data_df.loc[:, ['Name']]\n",
    "Account_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Rray9 Enterprises Llp to Rray9 Enterprises Llp (Match Score: 100)\n",
      "Updating Aces Infotech Pvt Ltd to Aces Infotech Pvt Ltd (Match Score: 100)\n",
      "Updating Qvc Realty Co. Limited to Qvc Realty Co. Limited (Match Score: 100)\n",
      "Updating Neco Industries Limited to Neco Industries Limited (Match Score: 100)\n",
      "Updating Tiger Logistics (India) Limited to Tiger Logistics (India) Limited (Match Score: 100)\n",
      "Updating Alox Industries Private Limited to Alox Industries Private Limited (Match Score: 100)\n",
      "Updating Harakh Chand Saraogi & Company Pvt.Ltd. to Harakh Chand Saraogi & Company Pvt.Ltd. (Match Score: 100)\n",
      "Updating Savannah Seeds Private Limited to Savannah Seeds Private Limited (Match Score: 100)\n",
      "Updating Avantha Technologies Limited to Avantha Technologies Limited (Match Score: 100)\n",
      "Updating Mark Software Systems Private Limited to Mark Software Systems Private Limited (Match Score: 100)\n",
      "Updating Flovel Energy Private Limited to Flovel Energy Private Limited (Match Score: 100)\n",
      "Updating Kapadia Associates Design Llp to Kapadia Associates Design Llp (Match Score: 100)\n",
      "Updating Ds & Associates Llp to Ds & Associates Llp (Match Score: 100)\n",
      "Updating Karl Storz Endoscopy India Private Limited to Karl Storz Endoscopy India Private Limited (Match Score: 100)\n",
      "Updating Templatolio Technologies Private Limited to Templatolio Technologies Private Limited (Match Score: 100)\n",
      "Updating Healthfore Technologies Limited to Healthfore Technologies Limited (Match Score: 100)\n",
      "Updating Quick Sort (India) Private Limited to Quick Sort (India) Private Limited (Match Score: 100)\n",
      "Updating Competent Synergies Private Limited to Competent Synergies Private Limited (Match Score: 100)\n",
      "Updating Spam Engineering Consultants Pvt. Ltd. to Spam Engineering Consultants Pvt. Ltd. (Match Score: 100)\n",
      "Updating Network Advertising Pvt Ltd to Network Advertising Pvt Ltd (Match Score: 100)\n",
      "Updating Jindal Saw Limited to Jindal Saw Limited (Match Score: 100)\n",
      "Updating Kalahanu Retail Venture Private Limited to Kalahanu Retail Venture Private Limited (Match Score: 100)\n",
      "Updating Grazitti Interactive Llp to Grazitti Interactive Llp (Match Score: 100)\n",
      "Updating Madhusudan Auto Private Limited to Madhusudan Auto Private Limited (Match Score: 100)\n",
      "Updating M&Ps Communications Pvt Ltd to M&Ps Communications Pvt Ltd (Match Score: 100)\n",
      "Company names updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "# Load CSV file\n",
    "file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define common terms to ignore\n",
    "ignore_terms = ['Limited', 'Private Limited', 'Pvt Ltd', 'Corp', 'LLC', 'Inc']\n",
    "\n",
    "# Function to clean and preprocess company names\n",
    "def preprocess_name(name):\n",
    "    # Convert to lowercase\n",
    "    name = name.lower()\n",
    "    # Remove terms from the ignore list\n",
    "    for term in ignore_terms:\n",
    "        name = re.sub(r'\\b' + re.escape(term.lower()) + r'\\b', '', name)\n",
    "    # Remove extra spaces and return the cleaned name\n",
    "    return ' '.join(name.split())\n",
    "\n",
    "# Preprocess company names in DataFrame\n",
    "df['Processed_Name'] = df['Name'].apply(preprocess_name)\n",
    "\n",
    "# Set up Selenium WebDriver using Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "def search_zauba_corp(company_name):\n",
    "    # Open ZaubaCorp website\n",
    "    driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "    # Find the search box and input the company name\n",
    "    search_box = driver.find_element(By.ID, \"searchid\")\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(company_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Parse the results page with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Extract company details (company name, company status, CIN, etc.)\n",
    "    details = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetching the correct company name as displayed on ZaubaCorp\n",
    "        search_results = soup.find_all('a', href=True)\n",
    "        # Extracting all company names from the search results\n",
    "        company_names_from_zauba = [result.text.strip() for result in search_results]\n",
    "        \n",
    "        # Use fuzzy matching to find the closest match to the original company name\n",
    "        if company_names_from_zauba:\n",
    "            best_match, match_score = process.extractOne(company_name, company_names_from_zauba, scorer=fuzz.token_sort_ratio)\n",
    "            details['Correct_Name'] = best_match if match_score > 70 else 'Not Found'\n",
    "        else:\n",
    "            details['Correct_Name'] = 'Not Found'\n",
    "    except AttributeError:\n",
    "        details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Separate DataFrames for different cases\n",
    "df_corrected = pd.DataFrame(columns=['Original_Name', 'Correct_Name'])\n",
    "df_not_found = pd.DataFrame(columns=['Original_Name'])\n",
    "df_holding_company = pd.DataFrame(columns=['Original_Name'])\n",
    "df_separate_company = pd.DataFrame(columns=['Original_Name'])\n",
    "\n",
    "# Loop through each company name in the CSV file\n",
    "for i, row in df.iterrows():\n",
    "    company = row['Name']\n",
    "    details = search_zauba_corp(company)\n",
    "    \n",
    "    # Handle different cases\n",
    "    if details['Correct_Name'] != 'Not Found':\n",
    "        corrected_name = details['Correct_Name'].title()  # Convert to Title Case\n",
    "        print(f\"Updating {company.title()} to {corrected_name} (Match Score: {fuzz.token_sort_ratio(company, corrected_name)})\")\n",
    "        df_corrected = pd.concat([df_corrected, pd.DataFrame({'Original_Name': [company.title()], 'Correct_Name': [corrected_name]})], ignore_index=True)\n",
    "    else:\n",
    "        # Check for corner cases\n",
    "        if 'holding company' in company.lower():\n",
    "            df_holding_company = pd.concat([df_holding_company, pd.DataFrame({'Original_Name': [company.title()]})], ignore_index=True)\n",
    "        elif 'separate company' in company.lower():\n",
    "            df_separate_company = pd.concat([df_separate_company, pd.DataFrame({'Original_Name': [company.title()]})], ignore_index=True)\n",
    "        else:\n",
    "            df_not_found = pd.concat([df_not_found, pd.DataFrame({'Original_Name': [company.title()]})], ignore_index=True)\n",
    "\n",
    "# Save DataFrames to separate CSV files\n",
    "df_corrected.to_csv('corrected_company_names.csv', index=False)\n",
    "df_not_found.to_csv('not_found_company_names.csv', index=False)\n",
    "df_holding_company.to_csv('holding_company_names.csv', index=False)\n",
    "df_separate_company.to_csv('separate_company_names.csv', index=False)\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Company names updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Id                                  Name Number of employees  \\\n",
      "0  2002150599             Mahathi Software Pvt Ltd.              51-200   \n",
      "1  2002153967                 RRAY9 ENTERPRISES LLP              10-Jan   \n",
      "2  2002153976  Koyo Bearings India Private Limited.              51-200   \n",
      "3  2002153986                                 BWSSC              51-200   \n",
      "4  2002154062                         A. V. Systems                 NaN   \n",
      "\n",
      "   Annual revenue                        Website              Phone  \\\n",
      "0             NaN  www.mahathi.com/contacts.html                NaN   \n",
      "1             NaN           nray.in/contact.html       098739 30018   \n",
      "2             NaN             www.jtekt.co.jp/e/                NaN   \n",
      "3             NaN                       bwssc.in                NaN   \n",
      "4             NaN    avsystems.co.in/contact-us/  '+91-11-26382324'   \n",
      "\n",
      "   Display phone                                            Address  \\\n",
      "0            NaN                              7380 Sand Lake Road,    \n",
      "1            NaN                      D - 195 Sector 10 , 1st Floor   \n",
      "2            NaN         Plot # 8-9, Sector 8, Industrial Model Twp   \n",
      "3            NaN       405, 4th Floor, DLF City Court Sikenderpur,    \n",
      "4            NaN  No. 7 / 29, Shyam Nagar, Behind Chandiwala, Es...   \n",
      "\n",
      "         City          State  ... Hosting Provider Renewal month  \\\n",
      "0  Suite 500     Orlando, FL  ...              NaN           NaN   \n",
      "1       Noida  Uttar Pradesh  ...              NaN           NaN   \n",
      "2       Bawal        Haryana  ...              NaN           NaN   \n",
      "3   Gurugram,        Haryana  ...              NaN           NaN   \n",
      "4   New Delhi         Delhi   ...              NaN           NaN   \n",
      "\n",
      "        Email Renewal Date  Present Email Service Provider  \\\n",
      "0  2017-08-22 18:30:00 UTC            Microsoft Office 365   \n",
      "1                      NaN            Microsoft Office 365   \n",
      "2                      NaN            Microsoft Office 365   \n",
      "3                      NaN            Microsoft Office 365   \n",
      "4                      NaN                          Google   \n",
      "\n",
      "  Cloud Billing Frequency Segment Microsoft Agreement  Account Type Tags  \\\n",
      "0                     NaN     NaN                 NaN           NaN  NaN   \n",
      "1                     NaN     NaN                 NaN           NaN  NaN   \n",
      "2                     NaN     NaN                 NaN           NaN  NaN   \n",
      "3                     NaN     NaN                 NaN           NaN  NaN   \n",
      "4                     NaN     NaN                 NaN           NaN  NaN   \n",
      "\n",
      "                      Standardized Name  \n",
      "0             Mahathi Software Pvt Ltd.  \n",
      "1                      Nray Enterprises  \n",
      "2  Koyo Bearings India Private Limited.  \n",
      "3                                 Bwssc  \n",
      "4                         A. V. Systems  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('Destination/anuj_100_fs_to_d365_transformed v1.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating RRAY9 ENTERPRISES LLP to RRAY9 ENTERPRISES LLP (ZaubaCorp suggestion)\n",
      "Updating ACES INFOTECH PVT LTD to ACES INFOTECH PVT LTD (ZaubaCorp suggestion)\n",
      "Updating QVC REALTY CO. LIMITED to QVC REALTY CO. LIMITED (ZaubaCorp suggestion)\n",
      "Updating NECO INDUSTRIES LIMITED to NECO INDUSTRIES LIMITED (ZaubaCorp suggestion)\n",
      "Updating TIGER LOGISTICS (INDIA) LIMITED to TIGER LOGISTICS (INDIA) LIMITED (ZaubaCorp suggestion)\n",
      "Updating ALOX INDUSTRIES PRIVATE LIMITED to ALOX INDUSTRIES PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating HARAKH CHAND SARAOGI & COMPANY PVT.LTD. to HARAKH CHAND SARAOGI & COMPANY PVT.LTD. (ZaubaCorp suggestion)\n",
      "Updating SAVANNAH SEEDS PRIVATE LIMITED to SAVANNAH SEEDS PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating AVANTHA TECHNOLOGIES LIMITED to AVANTHA TECHNOLOGIES LIMITED (ZaubaCorp suggestion)\n",
      "Updating MARK SOFTWARE SYSTEMS PRIVATE LIMITED to MARK SOFTWARE SYSTEMS PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating FLOVEL ENERGY PRIVATE LIMITED to FLOVEL ENERGY PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating KAPADIA ASSOCIATES DESIGN LLP to KAPADIA ASSOCIATES DESIGN LLP (ZaubaCorp suggestion)\n",
      "Updating DS & ASSOCIATES LLP to DS & ASSOCIATES LLP (ZaubaCorp suggestion)\n",
      "Updating KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED to KARL STORZ ENDOSCOPY INDIA PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED to TEMPLATOLIO TECHNOLOGIES PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating HEALTHFORE TECHNOLOGIES LIMITED to HEALTHFORE TECHNOLOGIES LIMITED (ZaubaCorp suggestion)\n",
      "Updating QUICK SORT (INDIA) PRIVATE LIMITED to QUICK SORT (INDIA) PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating COMPETENT SYNERGIES PRIVATE LIMITED to COMPETENT SYNERGIES PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating SPAM ENGINEERING CONSULTANTS PVT. LTD. to SPAM ENGINEERING CONSULTANTS PVT. LTD. (ZaubaCorp suggestion)\n",
      "Updating NETWORK ADVERTISING PVT LTD to NETWORK ADVERTISING PVT LTD (ZaubaCorp suggestion)\n",
      "Updating JINDAL SAW LIMITED to JINDAL SAW LIMITED (ZaubaCorp suggestion)\n",
      "Updating KALAHANU RETAIL VENTURE PRIVATE LIMITED to KALAHANU RETAIL VENTURE PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating GRAZITTI INTERACTIVE LLP to GRAZITTI INTERACTIVE LLP (ZaubaCorp suggestion)\n",
      "Updating MADHUSUDAN AUTO PRIVATE LIMITED to MADHUSUDAN AUTO PRIVATE LIMITED (ZaubaCorp suggestion)\n",
      "Updating M&PS COMMUNICATIONS PVT LTD to M&PS COMMUNICATIONS PVT LTD (ZaubaCorp suggestion)\n",
      "Company names updated and saved to update\\updated_company_names.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "# Load CSV file\n",
    "file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define folder for updates\n",
    "update_folder = \"update\"\n",
    "if not os.path.exists(update_folder):\n",
    "    os.makedirs(update_folder)  # Create the folder if it doesn't exist\n",
    "\n",
    "# Define common terms to ignore\n",
    "ignore_terms = ['Limited', 'Private Limited', 'Pvt Ltd', 'Corp', 'LLC', 'Inc',]\n",
    "\n",
    "# Function to clean and preprocess company names\n",
    "def preprocess_name(name):\n",
    "    # Convert to lowercase\n",
    "    name = name.lower()\n",
    "    # Remove terms from the ignore list\n",
    "    for term in ignore_terms:\n",
    "        name = re.sub(r'\\b' + re.escape(term.lower()) + r'\\b', '', name)\n",
    "    # Remove extra spaces and return the cleaned name\n",
    "    return ' '.join(name.split())\n",
    "\n",
    "# Preprocess company names in DataFrame\n",
    "df['Processed_Name'] = df['Name'].apply(preprocess_name)\n",
    "\n",
    "# Set up Selenium WebDriver using Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "def search_zauba_corp(company_name):\n",
    "    # Open ZaubaCorp website\n",
    "    driver.get('https://www.zaubacorp.com/')\n",
    "    \n",
    "    # Find the search box and input the company name\n",
    "    search_box = driver.find_element(By.ID, \"searchid\")\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(company_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Parse the results page with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Extract company details (company name, company status, CIN, etc.)\n",
    "    details = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetching the correct company name as displayed on ZaubaCorp\n",
    "        search_results = soup.find_all('a', href=True)\n",
    "        # Extracting all company names from the search results\n",
    "        company_names_from_zauba = [result.text.strip() for result in search_results]\n",
    "        \n",
    "        # Use fuzzy matching to find the closest match to the original company name\n",
    "        if company_names_from_zauba:\n",
    "            best_match, match_score = process.extractOne(company_name, company_names_from_zauba, scorer=fuzz.token_sort_ratio)\n",
    "            details['Correct_Name'] = best_match if match_score > 70 else 'Not Found'\n",
    "        else:\n",
    "            details['Correct_Name'] = 'Not Found'\n",
    "    except AttributeError:\n",
    "        details['Correct_Name'] = 'Not Found'\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Function to check if a name is in uppercase\n",
    "def is_name_uppercase(name):\n",
    "    return name.isupper()\n",
    "\n",
    "# Loop through each company name in the CSV file\n",
    "for i, row in df.iterrows():\n",
    "    company = row['Name']\n",
    "    details = search_zauba_corp(company)\n",
    "    \n",
    "    # Check if the ZaubaCorp name is found and is in uppercase\n",
    "    if details['Correct_Name'] != 'Not Found':\n",
    "        correct_name = details['Correct_Name']\n",
    "        if is_name_uppercase(correct_name):\n",
    "            print(f\"Updating {company} to {correct_name} (ZaubaCorp suggestion)\")\n",
    "            df.at[i, 'Name'] = correct_name  # Update the company name with the ZaubaCorp name\n",
    "\n",
    "# Save the updated DataFrame back to the CSV in the \"update\" folder\n",
    "updated_file_path = os.path.join(update_folder, 'updated_company_names.csv')\n",
    "df.to_csv(updated_file_path, index=False)\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(f\"Company names updated and saved to {updated_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "df['new_column']='Not_found'\n",
    "\n",
    "insert_pos = len(df)\n",
    "print(insert_pos)\n",
    "\n",
    "\n",
    "# columns = df.columns.tolist()\n",
    "# columns.insert(insert_pos, columns.pop(columns.index('new_column')))\n",
    "# df = df[columns]\n",
    "\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ID + _anuj_singh\n",
    "# Account name + \"_anuj_singh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Id                                               Name  \\\n",
      "0   _anuj_singh2002150599               Mahathi Software Pvt Ltd._anuj_singh   \n",
      "1   _anuj_singh2002153967                        Nray Enterprises_anuj_singh   \n",
      "2   _anuj_singh2002153976    Koyo Bearings India Private Limited._anuj_singh   \n",
      "3   _anuj_singh2002153986                                   BWSSC_anuj_singh   \n",
      "4   _anuj_singh2002154062                           A. V. Systems_anuj_singh   \n",
      "..                    ...                                                ...   \n",
      "95  _anuj_singh2002478777                Watrana Traction Company_anuj_singh   \n",
      "96  _anuj_singh2002478793                 Hans Infomatic Pvt Ltd._anuj_singh   \n",
      "97  _anuj_singh2002489788  Global Product Compliance Consultancy Services...   \n",
      "98  _anuj_singh2002494639                               The Hindu_anuj_singh   \n",
      "99  _anuj_singh2002503808                    Maratha Oil Refinery_anuj_singh   \n",
      "\n",
      "   Number of employees  Annual revenue                                Website  \\\n",
      "0               51-200             NaN          www.mahathi.com/contacts.html   \n",
      "1               10-Jan             NaN                   nray.in/contact.html   \n",
      "2               51-200             NaN                     www.jtekt.co.jp/e/   \n",
      "3               51-200             NaN                               bwssc.in   \n",
      "4                  NaN             NaN            avsystems.co.in/contact-us/   \n",
      "..                 ...             ...                                    ...   \n",
      "95              Nov-50             NaN                 www.forkliftspares.com   \n",
      "96              Nov-50             NaN  www.hansinfomatic.com/pages/index.htm   \n",
      "97              Nov-50             NaN                     www.globalpccs.com   \n",
      "98                 NaN             NaN                                    NaN   \n",
      "99                 NaN             NaN                                    NaN   \n",
      "\n",
      "                Phone  Display phone  \\\n",
      "0                 NaN            NaN   \n",
      "1        098739 30018            NaN   \n",
      "2                 NaN            NaN   \n",
      "3                 NaN            NaN   \n",
      "4   '+91-11-26382324'            NaN   \n",
      "..                ...            ...   \n",
      "95                NaN            NaN   \n",
      "96                NaN            NaN   \n",
      "97   '+91-9740000662'            NaN   \n",
      "98                NaN            NaN   \n",
      "99                NaN            NaN   \n",
      "\n",
      "                                              Address        City  \\\n",
      "0                               7380 Sand Lake Road,   Suite 500    \n",
      "1                       D - 195 Sector 10 , 1st Floor       Noida   \n",
      "2          Plot # 8-9, Sector 8, Industrial Model Twp       Bawal   \n",
      "3        405, 4th Floor, DLF City Court Sikenderpur,    Gurugram,   \n",
      "4   No. 7 / 29, Shyam Nagar, Behind Chandiwala, Es...   New Delhi   \n",
      "..                                                ...         ...   \n",
      "95                                                NaN         NaN   \n",
      "96                                                NaN         NaN   \n",
      "97  Product Compliance Consultancy Services #33, 1...   Bangalore   \n",
      "98                                                NaN         NaN   \n",
      "99  E/41, Mayoor 3RD Floor, Mtnl College Lane, Dad...      Mumbai   \n",
      "\n",
      "            State  ... Hosting Provider Renewal month  \\\n",
      "0     Orlando, FL  ...              NaN           NaN   \n",
      "1   Uttar Pradesh  ...              NaN           NaN   \n",
      "2         Haryana  ...              NaN           NaN   \n",
      "3         Haryana  ...              NaN           NaN   \n",
      "4          Delhi   ...              NaN           NaN   \n",
      "..            ...  ...              ...           ...   \n",
      "95            NaN  ...              NaN           NaN   \n",
      "96            NaN  ...              NaN           NaN   \n",
      "97      Karnataka  ...              NaN           NaN   \n",
      "98            NaN  ...              NaN           NaN   \n",
      "99    Maharashtra  ...              NaN           NaN   \n",
      "\n",
      "         Email Renewal Date  Present Email Service Provider  \\\n",
      "0   2017-08-22 18:30:00 UTC            Microsoft Office 365   \n",
      "1                       NaN            Microsoft Office 365   \n",
      "2                       NaN            Microsoft Office 365   \n",
      "3                       NaN            Microsoft Office 365   \n",
      "4                       NaN                          Google   \n",
      "..                      ...                             ...   \n",
      "95  2017-10-09 18:30:00 UTC                          Rediff   \n",
      "96  2017-10-29 18:30:00 UTC                          Others   \n",
      "97                      NaN            Microsoft Office 365   \n",
      "98                      NaN                             NaN   \n",
      "99                      NaN                             NaN   \n",
      "\n",
      "   Cloud Billing Frequency Segment Microsoft Agreement  Account Type Tags  \\\n",
      "0                      NaN     NaN                 NaN           NaN  NaN   \n",
      "1                      NaN     NaN                 NaN           NaN  NaN   \n",
      "2                      NaN     NaN                 NaN           NaN  NaN   \n",
      "3                      NaN     NaN                 NaN           NaN  NaN   \n",
      "4                      NaN     NaN                 NaN           NaN  NaN   \n",
      "..                     ...     ...                 ...           ...  ...   \n",
      "95                     NaN     NaN                 NaN           NaN  NaN   \n",
      "96                     NaN     NaN                 NaN           NaN  NaN   \n",
      "97                     NaN     NaN                 NaN           NaN  NaN   \n",
      "98                     NaN     NaN                 NaN           NaN  NaN   \n",
      "99                     NaN     NaN                 NaN           NaN  NaN   \n",
      "\n",
      "                                    Standardized Name  \n",
      "0                           Mahathi Software Pvt Ltd.  \n",
      "1                                    Nray Enterprises  \n",
      "2                Koyo Bearings India Private Limited.  \n",
      "3                                               Bwssc  \n",
      "4                                       A. V. Systems  \n",
      "..                                                ...  \n",
      "95                           Watrana Traction Company  \n",
      "96                            Hans Infomatic Pvt Ltd.  \n",
      "97  Global Product Compliance Consultancy Services...  \n",
      "98                                          The Hindu  \n",
      "99                               Maratha Oil Refinery  \n",
      "\n",
      "[100 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"Destination/anuj_100_fs_to_d365_transformed.csv\")\n",
    "id_column = 'Id'\n",
    "account_column = 'Name'\n",
    "if id_column in df.columns:\n",
    "    df[id_column] = '_anuj_singh' + df[id_column].astype(str)\n",
    "if account_column in df.columns:\n",
    "    df[account_column] = df[account_column].astype(str) + '_anuj_singh'\n",
    "df.to_csv('your_file_modified.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[\"123\",'1239',\"12375\"]\n",
    "a[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x1dd22e08360>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Company Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Company Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Iterate through each row in the dataframe\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# Company Name Correction\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     company_name \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCompany Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     90\u001b[0m     corrected_company_name \u001b[38;5;241m=\u001b[39m preprocess_name(company_name)\n\u001b[0;32m     91\u001b[0m     zauba_details \u001b[38;5;241m=\u001b[39m search_zauba_corp(corrected_company_name)\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Company Name'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import phonenumbers\n",
    "import validators\n",
    "from googlesearch import search as google_search\n",
    "\n",
    "# Load CSV file\n",
    "file_path = r'C:\\Users\\AnujSingh\\OneDrive - Foetron Consultancy Services Pvt Ltd\\Documents\\Foetron\\Coding\\D365AccountsETL\\Destination\\anuj_100_fs_to_d365_transformed v1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define folder for updates\n",
    "update_folder = \"update\"\n",
    "if not os.path.exists(update_folder):\n",
    "    os.makedirs(update_folder)\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Function to clean company names\n",
    "def preprocess_name(name):\n",
    "    return name.title().strip()\n",
    "\n",
    "# Function to search company names on ZaubaCorp\n",
    "def search_zauba_corp(company_name):\n",
    "    driver.get('https://www.zaubacorp.com/')\n",
    "    search_box = driver.find_element(By.ID, \"searchid\")\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    details = {}\n",
    "    try:\n",
    "        search_results = soup.find_all('a', href=True)\n",
    "        company_names_from_zauba = [result.text.strip() for result in search_results]\n",
    "        if company_names_from_zauba:\n",
    "            best_match, match_score = process.extractOne(company_name, company_names_from_zauba, scorer=fuzz.token_sort_ratio)\n",
    "            details['Correct_Name'] = best_match if match_score >= 75 else 'Not Found'\n",
    "        else:\n",
    "            details['Correct_Name'] = 'Not Found'\n",
    "    except Exception:\n",
    "        details['Correct_Name'] = 'Not Found'\n",
    "    return details\n",
    "\n",
    "# Standardize phone numbers using the phonenumbers library\n",
    "def standardize_phone(phone_number):\n",
    "    try:\n",
    "        parsed_phone = phonenumbers.parse(phone_number, \"IN\")  # Assuming phone numbers are Indian\n",
    "        if phonenumbers.is_valid_number(parsed_phone):\n",
    "            return phonenumbers.format_number(parsed_phone, phonenumbers.PhoneNumberFormat.INTERNATIONAL)\n",
    "    except phonenumbers.NumberParseException:\n",
    "        return \"Invalid\"\n",
    "    return \"Invalid\"\n",
    "\n",
    "# Standardize email addresses\n",
    "def standardize_email(email):\n",
    "    return email.lower().strip() if validators.email(email) else \"Invalid\"\n",
    "\n",
    "# Search for website on Google and match with 80% confidence\n",
    "def search_website(website):\n",
    "    try:\n",
    "        search_results = [result for result in google_search(website, num_results=5)]\n",
    "        best_match, match_score = process.extractOne(website, search_results, scorer=fuzz.token_sort_ratio)\n",
    "        if match_score >= 80:\n",
    "            return best_match\n",
    "    except Exception:\n",
    "        return \"Not Found\"\n",
    "    return \"Not Found\"\n",
    "\n",
    "# Standardize addresses (basic cleaning)\n",
    "def standardize_address(address):\n",
    "    address = address.replace(\"\\n\", \", \").strip()\n",
    "    return ' '.join(address.split()).title()\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for i, row in df.iterrows():\n",
    "    # Company Name Correction\n",
    "    company_name = row['Company Name']\n",
    "    corrected_company_name = preprocess_name(company_name)\n",
    "    zauba_details = search_zauba_corp(corrected_company_name)\n",
    "    \n",
    "    if zauba_details['Correct_Name'] != 'Not Found':\n",
    "        df.at[i, 'Company Name'] = zauba_details['Correct_Name']\n",
    "        print(f\"Updating {company_name} to {zauba_details['Correct_Name']}\")\n",
    "\n",
    "    # Phone Standardization\n",
    "    if 'Phone' in df.columns:\n",
    "        phone_number = row['Phone']\n",
    "        standardized_phone = standardize_phone(phone_number)\n",
    "        df.at[i, 'Phone'] = standardized_phone\n",
    "        print(f\"Standardized phone: {standardized_phone}\")\n",
    "\n",
    "    # Email Standardization\n",
    "    if 'Email' in df.columns:\n",
    "        email = row['Email']\n",
    "        standardized_email = standardize_email(email)\n",
    "        df.at[i, 'Email'] = standardized_email\n",
    "        print(f\"Standardized email: {standardized_email}\")\n",
    "\n",
    "    # Website Standardization\n",
    "    if 'Website' in df.columns:\n",
    "        website = row['Website']\n",
    "        matched_website = search_website(website)\n",
    "        if matched_website != \"Not Found\":\n",
    "            df.at[i, 'Website'] = matched_website\n",
    "            print(f\"Updated website: {matched_website}\")\n",
    "\n",
    "    # Address Standardization\n",
    "    if 'Address' in df.columns:\n",
    "        address = row['Address']\n",
    "        standardized_address = standardize_address(address)\n",
    "        df.at[i, 'Address'] = standardized_address\n",
    "        print(f\"Standardized address: {standardized_address}\")\n",
    "\n",
    "# Save the updated DataFrame back to a new CSV file\n",
    "updated_file_path = os.path.join(update_folder, 'updated_file.csv')\n",
    "df.to_csv(updated_file_path, index=False)\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(f\"Company names and other details updated successfully. File saved to {updated_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
